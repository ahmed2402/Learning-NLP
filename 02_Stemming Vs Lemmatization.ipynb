{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11d8468",
   "metadata": {},
   "source": [
    "## **What is Stemming?**\n",
    "Stemming is a process in natural language processing where we reduce a word to its base or root form. \n",
    "For example, the words \"playing\", \"played\", and \"plays\" can all be reduced to the root word \"play\".\n",
    "Stemming helps computers understand that these different forms of a word have a similar meaning.\n",
    "- Sentiment Analysis-- stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15080d0",
   "metadata": {},
   "source": [
    " ### **Popular Stemming Algorithms in NLTK**\n",
    "\n",
    "- **PorterStemmer**:  \n",
    "   One of the most widely used stemming algorithms. It uses a set of rules to iteratively remove common suffixes from English words. The Porter Stemmer is known for its simplicity and effectiveness, but sometimes it can be aggressive and may not always produce real words.\n",
    " \n",
    "- **LancasterStemmer**:  \n",
    "   A more aggressive stemmer compared to Porter. It applies a larger set of rules and can reduce words to very short stems, sometimes at the cost of accuracy. It is faster but may over-stem words, resulting in stems that are not always meaningful.\n",
    " \n",
    "- **RegexpStemmer**:  \n",
    "   This stemmer uses regular expressions to identify and remove suffixes from words. It is highly customizable, allowing users to define their own stemming rules using regex patterns. It is useful for specific use cases where custom stemming is required.\n",
    " \n",
    " - **SnowballStemmer**:  \n",
    "   Also known as the \"English Stemmer,\" it is an improvement over the Porter Stemmer. Snowball supports multiple languages and provides a balance between accuracy and aggressiveness. It is more flexible and often preferred for multilingual stemming tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0835b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random words for checking the stemmer\n",
    "words = [\"eating\", \"eats\", \"eaten\", \"eat\",\"historian\",\"history\",\"historical\",\"historically\",\"fruits\",\"fruit\",\"fruitful\",\"fruitfulness\",\"fruitful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629ee611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "eaten ---> eaten\n",
      "eat ---> eat\n",
      "historian ---> historian\n",
      "history ---> histori\n",
      "historical ---> histor\n",
      "historically ---> histor\n",
      "fruits ---> fruit\n",
      "fruit ---> fruit\n",
      "fruitful ---> fruit\n",
      "fruitfulness ---> fruit\n",
      "fruitful ---> fruit\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ---> {porter_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c403928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "eaten ---> eat\n",
      "eat ---> eat\n",
      "historian ---> hist\n",
      "history ---> hist\n",
      "historical ---> hist\n",
      "historically ---> hist\n",
      "fruits ---> fruit\n",
      "fruit ---> fruit\n",
      "fruitful ---> fruit\n",
      "fruitfulness ---> fruit\n",
      "fruitful ---> fruit\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ---> {lancaster.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a94b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eats\n",
      "eaten ---> eaten\n",
      "eat ---> eat\n",
      "historian ---> historian\n",
      "history ---> history\n",
      "historical ---> historical\n",
      "historically ---> historic\n",
      "fruits ---> fruit\n",
      "fruit ---> fruit\n",
      "fruitful ---> fruit\n",
      "fruitfulness ---> fruit\n",
      "fruitful ---> fruit\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "regex = RegexpStemmer('ing|s$|en$|ally$|fulness$|ful$', min=6)\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ---> {regex.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18ec991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eats\n",
      "eaten ---> eaten\n",
      "eat ---> eat\n",
      "historian ---> historian\n",
      "history ---> history\n",
      "historical ---> historical\n",
      "historically ---> historic\n",
      "fruits ---> fruit\n",
      "fruit ---> fruit\n",
      "fruitful ---> fruit\n",
      "fruitfulness ---> fruit\n",
      "fruitful ---> fruit\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english' ,  ignore_stopwords = False)\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word} ---> {regex.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828be83",
   "metadata": {},
   "source": [
    "## Wordnet Lemmatizer\n",
    "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
    "\n",
    "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma.\n",
    "\n",
    "- Chatbot---lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963605b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Zainab\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a14d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating --> eat\n",
      "eats --> eat\n",
      "eaten --> eat\n",
      "eat --> eat\n",
      "historian --> historian\n",
      "history --> history\n",
      "historical --> historical\n",
      "historically --> historically\n",
      "fruits --> fruit\n",
      "fruit --> fruit\n",
      "fruitful --> fruitful\n",
      "fruitfulness --> fruitfulness\n",
      "fruitful --> fruitful\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "'''\n",
    "POS- Noun-n\n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "for word in words:\n",
    "    print(f\"{word} --> {lemmatizer.lemmatize(word, pos='v')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee11e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f668b4d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
