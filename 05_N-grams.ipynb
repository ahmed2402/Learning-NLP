{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b063145",
   "metadata": {},
   "source": [
    "# N-grams in NLP: Simple Explanation\n",
    "\n",
    "N-grams are a fundamental concept in Natural Language Processing (NLP). In simple words, an n-gram is a sequence of 'n' words that appear together in a text. For example, in the sentence \"I love NLP\", the 2-grams (bigrams) are \"I love\" and \"love NLP\".\n",
    "\n",
    "## Basic Terminologies\n",
    "\n",
    "- **Token**: A single unit of text, usually a word.\n",
    "- **Unigram**: An n-gram where n=1 (single word).\n",
    "- **Bigram**: An n-gram where n=2 (two consecutive words).\n",
    "- **Trigram**: An n-gram where n=3 (three consecutive words).\n",
    "- **N-gram**: A general term for any sequence of 'n' consecutive tokens.\n",
    "- **Corpus**: A large collection of text used for analysis.\n",
    "- **Frequency**: The number of times a particular n-gram appears in the text.\n",
    "- **Context**: The surrounding words or tokens around a given word or n-gram.\n",
    "\n",
    "N-grams help in understanding the structure and patterns in language, and are widely used in tasks like text prediction, machine translation, and speech recognition.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
