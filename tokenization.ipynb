{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774bb4fd",
   "metadata": {},
   "source": [
    "## Tokenization in NLP using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00415759",
   "metadata": {},
   "source": [
    "### Terms in Tokenization\n",
    "- **'punkt'**: Pre-trained model in NLTK for sentence and word tokenization.\n",
    "- **'punkt_tab'**: Provides additional data for 'punkt'.\n",
    "- **sent_tokenize**: Splits text into sentences.\n",
    "- **word_tokenize**: Splits text into words.\n",
    "- **wordpunct_tokenize**: Splits text into words and punctuation.\n",
    "- **TreebankWordTokenizer**: Splits text using Penn Treebank conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c32758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Zainab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Zainab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') #a pre-trained model for splitting text into words/sentences\n",
    "nltk.download('punkt_tab') #a pre-trained model for splitting text into words/sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2348f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nThe quick brown fox jumps over the lazy dog.', 'The cat is eating the mouse.', \"The dog's is barking at the cat!\", 'The mouse is running away from the dog.', 'The cat!', 'is chasing the mouse.']\n"
     ]
    }
   ],
   "source": [
    "#paragraph to sentence\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#sent_tokenize splits the sentences on the basis of fullstops and !\n",
    "#paragraph to sentence\n",
    "corpus = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog.\n",
    "The cat is eating the mouse.\n",
    "The dog's is barking at the cat!\n",
    "The mouse is running away from the dog.\n",
    "The cat! is chasing the mouse.\n",
    "\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(corpus)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumps',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'eating',\n",
       " 'the',\n",
       " 'mouse',\n",
       " '.',\n",
       " 'The',\n",
       " 'dog',\n",
       " \"'s\",\n",
       " 'is',\n",
       " 'barking',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cat',\n",
       " '!',\n",
       " 'The',\n",
       " 'mouse',\n",
       " 'is',\n",
       " 'running',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'dog',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " '!',\n",
       " 'is',\n",
       " 'chasing',\n",
       " 'the',\n",
       " 'mouse',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paragraph to words\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38fd23e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumps',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'eating',\n",
       " 'the',\n",
       " 'mouse',\n",
       " '.',\n",
       " 'The',\n",
       " 'dog',\n",
       " \"'\",\n",
       " 's',\n",
       " 'is',\n",
       " 'barking',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cat',\n",
       " '!',\n",
       " 'The',\n",
       " 'mouse',\n",
       " 'is',\n",
       " 'running',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'dog',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " '!',\n",
       " 'is',\n",
       " 'chasing',\n",
       " 'the',\n",
       " 'mouse',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d823cb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumps',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'eating',\n",
       " 'the',\n",
       " 'mouse.',\n",
       " 'The',\n",
       " 'dog',\n",
       " \"'s\",\n",
       " 'is',\n",
       " 'barking',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cat',\n",
       " '!',\n",
       " 'The',\n",
       " 'mouse',\n",
       " 'is',\n",
       " 'running',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'dog.',\n",
       " 'The',\n",
       " 'cat',\n",
       " '!',\n",
       " 'is',\n",
       " 'chasing',\n",
       " 'the',\n",
       " 'mouse',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
